# æ€§èƒ½è°ƒä¼˜ï¼šè®©ç³»ç»Ÿé£èµ·æ¥

> **ç³»åˆ—æ–‡ç« ï¼šæ„å»ºä¸‹ä¸€ä»£ä»»åŠ¡è°ƒåº¦å¹³å°**  
> ç¬¬å…­ç¯‡ï¼šæ€§èƒ½ç¯‡ - å‹æµ‹ã€è°ƒä¼˜ä¸æœ€ä½³å®è·µ

---

## ğŸ“‹ ç›®å½•

- [å¼•è¨€](#å¼•è¨€)
- [æ€§èƒ½æµ‹è¯•æ–¹æ³•](#æ€§èƒ½æµ‹è¯•æ–¹æ³•)
- [Actorç³»ç»Ÿè°ƒä¼˜](#actorç³»ç»Ÿè°ƒä¼˜)
- [Streamsæ€§èƒ½ä¼˜åŒ–](#streamsæ€§èƒ½ä¼˜åŒ–)
- [é›†ç¾¤æ€§èƒ½è°ƒä¼˜](#é›†ç¾¤æ€§èƒ½è°ƒä¼˜)
- [JVMè°ƒä¼˜](#jvmè°ƒä¼˜)
- [å‹æµ‹ä¸åŸºå‡†æµ‹è¯•](#å‹æµ‹ä¸åŸºå‡†æµ‹è¯•)
- [ç›‘æ§ä¸åˆ†æ](#ç›‘æ§ä¸åˆ†æ)
- [ç”Ÿäº§ç¯å¢ƒç»éªŒ](#ç”Ÿäº§ç¯å¢ƒç»éªŒ)

---

## å¼•è¨€

å‰é¢5ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬æ„å»ºäº†å®Œæ•´çš„åˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿã€‚ä½†**ç³»ç»Ÿèƒ½ä¸èƒ½æŠ—ä½ç”Ÿäº§è´Ÿè½½ï¼Ÿ**è¿™æ˜¯å…³é”®é—®é¢˜ã€‚

æœ¬æ–‡å°†æ·±å…¥æ€§èƒ½è°ƒä¼˜ï¼ŒåŒ…æ‹¬ï¼š

- ğŸ“Š **æ€§èƒ½æµ‹è¯•**ï¼šå¦‚ä½•ç§‘å­¦åœ°æµ‹è¯•æ€§èƒ½
- âš¡ **Actorè°ƒä¼˜**ï¼šDispatcherã€Mailboxä¼˜åŒ–
- ğŸš° **Streamsè°ƒä¼˜**ï¼šèƒŒå‹ã€æ‰¹é‡ã€å¹¶å‘
- ğŸŒ **é›†ç¾¤è°ƒä¼˜**ï¼šShardingã€ç½‘ç»œã€åºåˆ—åŒ–
- ğŸ”¥ **å‹æµ‹å®æˆ˜**ï¼šJMeterã€Gatlingå‹åŠ›æµ‹è¯•
- ğŸ“ˆ **ç›‘æ§åˆ†æ**ï¼šPrometheusã€Grafanaå¯è§†åŒ–

### æ€§èƒ½ç›®æ ‡

| æŒ‡æ ‡ | ç›®æ ‡å€¼ | è¯´æ˜ |
|-----|-------|------|
| **APIå“åº”æ—¶é—´** | P99 < 100ms | 99%è¯·æ±‚100mså†… |
| **å·¥ä½œæµåå** | 10000/s | æ¯ç§’å¤„ç†1ä¸‡ä¸ªå·¥ä½œæµ |
| **é›†ç¾¤æ¢å¤** | < 5s | èŠ‚ç‚¹æ•…éšœ5ç§’å†…æ¢å¤ |
| **CPUä½¿ç”¨ç‡** | 60-70% | ç•™æœ‰ä½™é‡åº”å¯¹çªå‘ |
| **å†…å­˜ä½¿ç”¨** | < 80% | é¿å…é¢‘ç¹GC |
| **å¯ç”¨æ€§** | 99.99% | å¹´æ•…éšœæ—¶é—´<53åˆ†é’Ÿ |

---

## æ€§èƒ½æµ‹è¯•æ–¹æ³•

### æµ‹è¯•ç±»å‹

#### 1. åŸºå‡†æµ‹è¯•ï¼ˆBenchmarkï¼‰

**ç›®æ ‡**ï¼šæµ‹è¯•å•ä¸ªç»„ä»¶çš„æé™æ€§èƒ½

```scala
import org.openjdk.jmh.annotations._
import java.util.concurrent.TimeUnit

@State(Scope.Thread)
@BenchmarkMode(Array(Mode.Throughput))
@OutputTimeUnit(TimeUnit.SECONDS)
class ActorBenchmark {
  
  var system: ActorSystem[_] = _
  var actor: ActorRef[Command] = _
  
  @Setup
  def setup(): Unit = {
    system = ActorSystem(Behaviors.empty, "benchmark")
    actor = system.systemActorOf(WorkflowActor(/*...*/), "workflow")
  }
  
  @Benchmark
  def sendMessage(): Unit = {
    actor ! Execute(replyTo)
  }
  
  @TearDown
  def teardown(): Unit = {
    system.terminate()
  }
}
```

**è¿è¡Œ**ï¼š
```bash
sbt "jmh:run -i 10 -wi 5 -f 1 -t 4"
# -i: è¿­ä»£æ¬¡æ•°  -wi: é¢„çƒ­æ¬¡æ•°  -f: forkæ¬¡æ•°  -t: çº¿ç¨‹æ•°
```

#### 2. è´Ÿè½½æµ‹è¯•ï¼ˆLoad Testï¼‰

**ç›®æ ‡**ï¼šæµ‹è¯•ç³»ç»Ÿåœ¨é¢„æœŸè´Ÿè½½ä¸‹çš„è¡¨ç°

```scala
// Gatlingè´Ÿè½½æµ‹è¯•
class WorkflowLoadTest extends Simulation {
  
  val httpProtocol = http
    .baseUrl("http://localhost:8080")
    .acceptHeader("application/json")
  
  val scn = scenario("WorkflowExecution")
    .exec(
      http("åˆ›å»ºå·¥ä½œæµ")
        .post("/api/v1/workflows")
        .body(StringBody("""{"id": "wf-${id}", "name": "test"}"""))
        .check(status.is(200))
    )
    .pause(1)
    .exec(
      http("æ‰§è¡Œå·¥ä½œæµ")
        .post("/api/v1/workflows/${id}/execute")
        .check(status.is(200))
    )
  
  setUp(
    scn.inject(
      rampUsers(1000) during (60.seconds),  // 60ç§’å†…åŠ è½½1000ç”¨æˆ·
      constantUsersPerSec(100) during (300.seconds)  // æŒç»­100 QPS 5åˆ†é’Ÿ
    )
  ).protocols(httpProtocol)
}
```

#### 3. å‹åŠ›æµ‹è¯•ï¼ˆStress Testï¼‰

**ç›®æ ‡**ï¼šæµ‹è¯•ç³»ç»Ÿçš„æé™æ‰¿å—èƒ½åŠ›

```scala
setUp(
  scn.inject(
    rampUsers(100) during (10.seconds),
    rampUsers(500) during (20.seconds),
    rampUsers(1000) during (30.seconds),
    constantUsersPerSec(200) during (60.seconds)  // æŒç»­æ–½å‹
  )
)
```

#### 4. æµ¸æ³¡æµ‹è¯•ï¼ˆSoak Testï¼‰

**ç›®æ ‡**ï¼šé•¿æ—¶é—´è¿è¡Œï¼Œå‘ç°å†…å­˜æ³„æ¼ç­‰é—®é¢˜

```scala
setUp(
  scn.inject(
    constantUsersPerSec(50) during (24.hours)  // æŒç»­24å°æ—¶
  )
)
```

### æ€§èƒ½æŒ‡æ ‡

#### å…³é”®æŒ‡æ ‡

```scala
case class PerformanceMetrics(
  throughput: Double,        // ååé‡ (req/s)
  latencyP50: Duration,      // ä¸­ä½æ•°å»¶è¿Ÿ
  latencyP95: Duration,      // 95åˆ†ä½å»¶è¿Ÿ
  latencyP99: Duration,      // 99åˆ†ä½å»¶è¿Ÿ
  errorRate: Double,         // é”™è¯¯ç‡
  cpuUsage: Double,          // CPUä½¿ç”¨ç‡
  memoryUsage: Long,         // å†…å­˜ä½¿ç”¨
  gcTime: Duration           // GCæ—¶é—´
)
```

#### æµ‹é‡å·¥å…·

```scala
// ä½¿ç”¨Kamonç›‘æ§
val timer = Kamon.timer("workflow.execution.time")
val counter = Kamon.counter("workflow.execution.count")

val span = timer.start()
try {
  executeWorkflow(workflow)
  counter.increment()
} finally {
  span.stop()
}
```

---

## Actorç³»ç»Ÿè°ƒä¼˜

### Dispatcheré…ç½®

Dispatcheræ§åˆ¶Actoræ‰§è¡Œçº¿ç¨‹ï¼š

```hocon
# application.conf

# é»˜è®¤Dispatcherï¼ˆå…±äº«çº¿ç¨‹æ± ï¼‰
pekko.actor.default-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  
  fork-join-executor {
    # çº¿ç¨‹æ•° = cores * parallelism-factor
    parallelism-min = 8
    parallelism-factor = 3.0
    parallelism-max = 64
  }
  
  # ååé‡ï¼ˆæ¯æ¬¡å¤„ç†å¤šå°‘æ¶ˆæ¯ï¼‰
  throughput = 5
}

# é˜»å¡IOä¸“ç”¨Dispatcher
blocking-io-dispatcher {
  type = Dispatcher
  executor = "thread-pool-executor"
  
  thread-pool-executor {
    fixed-pool-size = 32  # å›ºå®šçº¿ç¨‹æ± 
  }
  
  throughput = 1  # é˜»å¡æ“ä½œthroughputè®¾ä¸º1
}

# CPUå¯†é›†å‹Dispatcher
cpu-intensive-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  
  fork-join-executor {
    parallelism-min = 4
    parallelism-factor = 1.0  # cores * 1
    parallelism-max = 16
  }
  
  throughput = 10  # CPUå¯†é›†å‹å¯ä»¥æ›´é«˜
}
```

**ä½¿ç”¨è‡ªå®šä¹‰Dispatcher**ï¼š

```scala
// æ–¹å¼1ï¼šé…ç½®ä¸­æŒ‡å®š
pekko.actor.deployment {
  /workflow-supervisor/* {
    dispatcher = blocking-io-dispatcher
  }
}

// æ–¹å¼2ï¼šä»£ç ä¸­æŒ‡å®š
context.spawn(
  WorkflowActor(/*...*/),
  "workflow",
  DispatcherSelector.fromConfig("blocking-io-dispatcher")
)
```

### Mailboxä¼˜åŒ–

```hocon
# æœ‰ç•ŒMailboxï¼ˆé˜²æ­¢OOMï¼‰
bounded-mailbox {
  mailbox-type = "org.apache.pekko.dispatch.BoundedMailbox"
  mailbox-capacity = 10000
  mailbox-push-timeout-time = 100ms
}

# ä¼˜å…ˆçº§Mailbox
priority-mailbox {
  mailbox-type = "cn.xuyinyin.magic.PriorityMailbox"
}
```

**è‡ªå®šä¹‰ä¼˜å…ˆçº§Mailbox**ï¼š

```scala
class PriorityMailbox extends UnboundedPriorityMailbox(
  PriorityGenerator {
    case Execute(_) => 0      // é«˜ä¼˜å…ˆçº§
    case GetStatus(_) => 1    // ä¸­ä¼˜å…ˆçº§
    case Stop => 2            // ä½ä¼˜å…ˆçº§
    case _ => 1
  }
)
```

### Actorè®¾è®¡ä¼˜åŒ–

#### 1. é¿å…é˜»å¡

```scala
// âŒ é”™è¯¯ï¼šé˜»å¡Actor
Behaviors.receiveMessage {
  case FetchData(id) =>
    val data = database.query(id)  // é˜»å¡ï¼
    sender ! data
    Behaviors.same
}

// âœ… æ­£ç¡®ï¼šä½¿ç”¨Future + pipeToSelf
Behaviors.receiveMessage {
  case FetchData(id) =>
    context.pipeToSelf(Future {
      database.query(id)  // åœ¨Futureä¸­æ‰§è¡Œ
    }(blockingDispatcher)) {
      case Success(data) => DataFetched(data)
      case Failure(ex) => FetchFailed(ex)
    }
    Behaviors.same
}
```

#### 2. æ‰¹é‡å¤„ç†

```scala
// æ‰¹é‡å¤„ç†æ¶ˆæ¯
def batching(buffer: List[Item], batchSize: Int): Behavior[Command] = {
  Behaviors.withTimers { timers =>
    Behaviors.receiveMessage {
      case AddItem(item) =>
        val newBuffer = buffer :+ item
        
        if (newBuffer.size >= batchSize) {
          processBatch(newBuffer)
          batching(List.empty, batchSize)
        } else {
          if (buffer.isEmpty) {
            timers.startSingleTimer(FlushBatch, 1.second)
          }
          batching(newBuffer, batchSize)
        }
      
      case FlushBatch if buffer.nonEmpty =>
        processBatch(buffer)
        batching(List.empty, batchSize)
    }
  }
}
```

#### 3. æ¶ˆæ¯èšåˆ

```scala
// Aggregatoræ¨¡å¼ï¼šæ”¶é›†å¤šä¸ªå“åº”
def aggregating(
  remaining: Int,
  responses: List[Response]
): Behavior[Command] = {
  Behaviors.receiveMessage {
    case resp: Response =>
      val newResponses = responses :+ resp
      val newRemaining = remaining - 1
      
      if (newRemaining == 0) {
        // æ‰€æœ‰å“åº”æ”¶é›†å®Œæˆ
        processAllResponses(newResponses)
        Behaviors.stopped
      } else {
        aggregating(newRemaining, newResponses)
      }
  }
}
```

---

## Streamsæ€§èƒ½ä¼˜åŒ–

### 1. æ‰¹é‡å¤„ç†

```scala
// âŒ é€æ¡å¤„ç†
Source(records)
  .mapAsync(1)(record => database.insert(record))  // æ…¢ï¼
  .runWith(Sink.ignore)

// âœ… æ‰¹é‡å¤„ç†
Source(records)
  .grouped(1000)                                   // æ‰¹é‡
  .mapAsync(4)(batch => database.batchInsert(batch))  // å¹¶å‘
  .runWith(Sink.ignore)

// æ€§èƒ½æå‡ï¼š50-100x
```

### 2. å¼‚æ­¥è¾¹ç•Œ

```scala
// âŒ å•çº¿ç¨‹
Source(data)
  .map(cpuIntensive1)  // çº¿ç¨‹1
  .map(cpuIntensive2)  // çº¿ç¨‹1
  .runWith(Sink.ignore)

// âœ… å¤šçº¿ç¨‹
Source(data)
  .map(cpuIntensive1)
  .async  // å¼‚æ­¥è¾¹ç•Œ
  .map(cpuIntensive2)
  .async
  .runWith(Sink.ignore)

// æ€§èƒ½æå‡ï¼šå¤šæ ¸åˆ©ç”¨
```

### 3. ç¼“å†²åŒºè°ƒä¼˜

```scala
// å¢å¤§ç¼“å†²åŒº
Source(data)
  .withAttributes(
    Attributes.inputBuffer(
      initial = 128,
      max = 256
    )
  )
  .map(transform)
  .runWith(Sink.ignore)

// æ€§èƒ½æå‡ï¼š20-30%
```

### 4. mapAsyncå¹¶å‘åº¦

```scala
// è°ƒä¼˜å¹¶å‘åº¦
Source(urls)
  .mapAsync(parallelism = 16) { url =>  // æ ¹æ®åœºæ™¯è°ƒæ•´
    Http().singleRequest(HttpRequest(uri = url))
  }
  .runWith(Sink.ignore)

// ç»éªŒå€¼ï¼š
// CPUå¯†é›†ï¼šcores
// IOå¯†é›†ï¼šcores * 2-4
// ç½‘ç»œè¯·æ±‚ï¼š10-20
```

### 5. èƒŒå‹ç­–ç•¥

```scala
// é€‰æ‹©åˆé€‚çš„èƒŒå‹ç­–ç•¥
Source.tick(0.seconds, 10.millis, 1)
  .buffer(1000, OverflowStrategy.dropHead)  // ä¸¢å¼ƒæ—§æ•°æ®
  .map(process)
  .runWith(Sink.ignore)

// ç­–ç•¥ï¼š
// backpressure: é˜»å¡ä¸Šæ¸¸ï¼ˆé»˜è®¤ï¼‰
// dropHead: ä¸¢å¼ƒæœ€æ—§
// dropTail: ä¸¢å¼ƒæœ€æ–°
// dropNew: ä¸¢å¼ƒæ–°æ•°æ®
// fail: å¤±è´¥
```

### æ€§èƒ½å¯¹æ¯”

| ä¼˜åŒ– | åœºæ™¯ | æå‡ |
|-----|------|------|
| grouped(1000) | æ•°æ®åº“æ‰¹é‡å†™å…¥ | **50-100x** |
| mapAsync(16) | HTTPå¹¶å‘è¯·æ±‚ | **10-20x** |
| asyncè¾¹ç•Œ | CPUå¯†é›†è®¡ç®— | **2-4x** |
| bufferå¢å¤§ | é«˜ååæµ | **20-30%** |

---

## é›†ç¾¤æ€§èƒ½è°ƒä¼˜

### 1. åºåˆ—åŒ–ä¼˜åŒ–

```hocon
# ä½¿ç”¨é«˜æ•ˆåºåˆ—åŒ–
pekko.actor {
  serializers {
    jackson-cbor = "org.apache.pekko.serialization.jackson.JacksonCborSerializer"
    kryo = "io.altoo.akka.serialization.kryo.KryoSerializer"
  }
  
  serialization-bindings {
    "cn.xuyinyin.magic.CborSerializable" = jackson-cbor
    "cn.xuyinyin.magic.KryoSerializable" = kryo
  }
}

# Kryoé…ç½®ï¼ˆæœ€å¿«ï¼‰
pekko-kryo-serialization {
  type = "graph"
  id-strategy = "explicit"
  implicit-registration-logging = true
  kryo-trace = false
}
```

**æ€§èƒ½å¯¹æ¯”**ï¼š
- Javaåºåˆ—åŒ–ï¼šæ…¢ã€ä½“ç§¯å¤§
- Jackson CBORï¼šå¿«ã€ä½“ç§¯ä¸­ç­‰
- Kryoï¼šæœ€å¿«ã€ä½“ç§¯æœ€å°

### 2. Shardingä¼˜åŒ–

```hocon
pekko.cluster.sharding {
  # Shardæ•°é‡ï¼ˆå»ºè®®10 * èŠ‚ç‚¹æ•°ï¼‰
  number-of-shards = 100
  
  # å†å¹³è¡¡ç­–ç•¥
  least-shard-allocation-strategy {
    rebalance-threshold = 2
    max-simultaneous-rebalance = 3
  }
  
  # å¿ƒè·³é—´éš”
  coordinator-state {
    write-majority-plus = 3
  }
  
  # Passivationï¼ˆé—²ç½®Entityæ¸…ç†ï¼‰
  passivate-idle-entity-after = 2.minutes
}
```

### 3. ç½‘ç»œä¼˜åŒ–

```hocon
pekko.remote.artery {
  # ä¼ è¾“å±‚
  transport = tcp
  
  canonical {
    hostname = "0.0.0.0"
    port = 2551
  }
  
  # TCPä¼˜åŒ–
  advanced {
    # æœ€å¤§å¸§å¤§å°
    maximum-frame-size = 256000b
    
    # ç¼“å†²åŒºå¤§å°
    send-buffer-size = 256000b
    receive-buffer-size = 256000b
    
    # è¿æ¥æ± 
    outbound-message-queue-size = 3072
    
    # å‹ç¼©
    compression {
      enabled = off  # é€šå¸¸ä¸éœ€è¦
    }
  }
}
```

### 4. é›†ç¾¤ç›‘æ§

```hocon
pekko.cluster {
  # å¿ƒè·³é—´éš”
  failure-detector {
    threshold = 12.0
    acceptable-heartbeat-pause = 5s
    heartbeat-interval = 1s
  }
  
  # Gossipä¼˜åŒ–
  gossip-interval = 1s
  gossip-time-to-live = 2s
  
  # é¢†å¯¼è€…é€‰ä¸¾
  leader-actions-interval = 1s
}
```

---

## JVMè°ƒä¼˜

### GCé…ç½®

```bash
# G1GCï¼ˆæ¨èï¼‰
java -Xms4g -Xmx4g \
  -XX:+UseG1GC \
  -XX:MaxGCPauseMillis=200 \
  -XX:InitiatingHeapOccupancyPercent=45 \
  -XX:G1HeapRegionSize=16m \
  -XX:+ParallelRefProcEnabled \
  -XX:+UseStringDeduplication \
  -jar pekko-server.jar

# ZGCï¼ˆä½å»¶è¿Ÿï¼‰
java -Xms4g -Xmx4g \
  -XX:+UseZGC \
  -XX:ZCollectionInterval=5 \
  -jar pekko-server.jar
```

### JVMå‚æ•°

```bash
# æ€§èƒ½ç›‘æ§
-XX:+PrintGCDetails \
-XX:+PrintGCDateStamps \
-Xloggc:gc.log \
-XX:+HeapDumpOnOutOfMemoryError \
-XX:HeapDumpPath=/tmp/heapdump.hprof

# ä¼˜åŒ–å‚æ•°
-XX:+AggressiveOpts \
-XX:+UseFastAccessorMethods \
-XX:+OptimizeStringConcat \
-XX:+UseCompressedOops

# çº¿ç¨‹å‚æ•°
-XX:ThreadStackSize=512k \
-XX:ActiveProcessorCount=16
```

### å †å†…å­˜é…ç½®

```
# å †å¤§å°å»ºè®®
å°å‹åº”ç”¨ï¼š2-4GB
ä¸­å‹åº”ç”¨ï¼š8-16GB
å¤§å‹åº”ç”¨ï¼š32-64GB

# åŸåˆ™ï¼š
1. Xms = Xmxï¼ˆé¿å…åŠ¨æ€è°ƒæ•´ï¼‰
2. é¢„ç•™30%ç»™æ“ä½œç³»ç»Ÿ
3. é¿å…è¶…è¿‡32GBï¼ˆå‹ç¼©æŒ‡é’ˆå¤±æ•ˆï¼‰
```

---

## å‹æµ‹ä¸åŸºå‡†æµ‹è¯•

### Gatlingå‹æµ‹

```scala
class FullLoadTest extends Simulation {
  
  val httpProtocol = http
    .baseUrl("http://localhost:8080")
    .acceptHeader("application/json")
  
  // åœºæ™¯1ï¼šåˆ›å»ºå·¥ä½œæµ
  val createWorkflow = scenario("CreateWorkflow")
    .exec(
      http("åˆ›å»º")
        .post("/api/v1/workflows")
        .body(StringBody("""{"id": "wf-${id}"}"""))
        .check(status.is(200))
    )
  
  // åœºæ™¯2ï¼šæ‰§è¡Œå·¥ä½œæµ
  val executeWorkflow = scenario("ExecuteWorkflow")
    .exec(
      http("æ‰§è¡Œ")
        .post("/api/v1/workflows/wf-${workflowId}/execute")
        .check(status.is(200))
    )
  
  // åœºæ™¯3ï¼šæŸ¥è¯¢çŠ¶æ€
  val queryStatus = scenario("QueryStatus")
    .exec(
      http("æŸ¥è¯¢")
        .get("/api/v1/workflows/wf-${workflowId}/status")
        .check(status.is(200))
    )
  
  setUp(
    createWorkflow.inject(rampUsers(100) during (10.seconds)),
    executeWorkflow.inject(
      rampUsers(500) during (30.seconds),
      constantUsersPerSec(200) during (300.seconds)
    ),
    queryStatus.inject(constantUsersPerSec(100) during (300.seconds))
  ).protocols(httpProtocol)
  .assertions(
    global.responseTime.percentile(95).lt(100),  // P95 < 100ms
    global.successfulRequests.percent.gt(99)      // æˆåŠŸç‡ > 99%
  )
}
```

### è¿è¡Œå‹æµ‹

```bash
# Gatling
sbt "gatling:testOnly FullLoadTest"

# ç”ŸæˆæŠ¥å‘Š
open target/gatling/fullloadtest-{timestamp}/index.html
```

### ç»“æœåˆ†æ

```
å‹æµ‹ç»“æœç¤ºä¾‹ï¼š

å…¨å±€æŒ‡æ ‡ï¼š
- è¯·æ±‚æ€»æ•°: 1,000,000
- æˆåŠŸç‡: 99.98%
- ååé‡: 3,333 req/s

å“åº”æ—¶é—´åˆ†å¸ƒï¼š
- P50: 15ms
- P75: 28ms
- P95: 65ms
- P99: 98ms
- Max: 250ms

é”™è¯¯åˆ†æï¼š
- Timeout: 150 (0.015%)
- 5xx: 50 (0.005%)
```

---

## ç›‘æ§ä¸åˆ†æ

### PrometheusæŒ‡æ ‡

```scala
// ä½¿ç”¨Kamon + Prometheus
libraryDependencies += "io.kamon" %% "kamon-prometheus" % "2.5.9"

// æš´éœ²æŒ‡æ ‡
Kamon.init()

// è‡ªå®šä¹‰æŒ‡æ ‡
val workflowCounter = Kamon.counter("workflow.execution.total")
val workflowTimer = Kamon.timer("workflow.execution.duration")
val activeWorkflows = Kamon.gauge("workflow.active.count")

// è®°å½•æŒ‡æ ‡
workflowCounter.withTag("status", "success").increment()
val span = workflowTimer.start()
try {
  executeWorkflow()
} finally {
  span.stop()
}
```

### Grafana Dashboard

```json
{
  "dashboard": {
    "title": "Pekko Scheduler Dashboard",
    "panels": [
      {
        "title": "å·¥ä½œæµååé‡",
        "targets": [{
          "expr": "rate(workflow_execution_total[1m])"
        }]
      },
      {
        "title": "å“åº”æ—¶é—´P99",
        "targets": [{
          "expr": "histogram_quantile(0.99, workflow_execution_duration_bucket)"
        }]
      },
      {
        "title": "Actor Mailbox Size",
        "targets": [{
          "expr": "pekko_actor_mailbox_size"
        }]
      },
      {
        "title": "é›†ç¾¤èŠ‚ç‚¹æ•°",
        "targets": [{
          "expr": "pekko_cluster_members"
        }]
      }
    ]
  }
}
```

### å…³é”®ç›‘æ§æŒ‡æ ‡

| ç±»åˆ« | æŒ‡æ ‡ | å‘Šè­¦é˜ˆå€¼ |
|-----|------|---------|
| **ååé‡** | workflow.execution.rate | < 100/s |
| **å»¶è¿Ÿ** | workflow.execution.p99 | > 500ms |
| **é”™è¯¯ç‡** | workflow.failure.rate | > 1% |
| **Actor** | actor.mailbox.size | > 10000 |
| **é›†ç¾¤** | cluster.unreachable.members | > 0 |
| **JVM** | jvm.memory.used.percent | > 85% |
| **GC** | jvm.gc.pause.max | > 1s |

---

## ç”Ÿäº§ç¯å¢ƒç»éªŒ

### æ€§èƒ½æ¸…å•

**éƒ¨ç½²å‰æ£€æŸ¥**ï¼š

- [ ] å¯ç”¨G1GCæˆ–ZGC
- [ ] é…ç½®åˆé€‚çš„å †å†…å­˜ï¼ˆXms=Xmxï¼‰
- [ ] ä½¿ç”¨é«˜æ•ˆåºåˆ—åŒ–ï¼ˆKryo/CBORï¼‰
- [ ] é…ç½®Dispatcherï¼ˆé¿å…é˜»å¡é»˜è®¤Dispatcherï¼‰
- [ ] å¯ç”¨Cluster Sharding
- [ ] é…ç½®Split Brain Resolver
- [ ] è®¾ç½®åˆç†çš„Mailboxå®¹é‡
- [ ] å¯ç”¨Prometheusç›‘æ§
- [ ] é…ç½®Grafanaå‘Šè­¦

### å¸¸è§æ€§èƒ½é—®é¢˜

#### 1. Actor Mailboxæº¢å‡º

**ç—‡çŠ¶**ï¼šOOMã€å“åº”å˜æ…¢

**è§£å†³**ï¼š
```hocon
bounded-mailbox {
  mailbox-capacity = 10000
  mailbox-push-timeout-time = 100ms
}
```

#### 2. é˜»å¡é»˜è®¤Dispatcher

**ç—‡çŠ¶**ï¼šæ•´ä¸ªç³»ç»Ÿå¡ä½

**è§£å†³**ï¼šä½¿ç”¨ç‹¬ç«‹Dispatcherå¤„ç†é˜»å¡æ“ä½œ

#### 3. åºåˆ—åŒ–ç“¶é¢ˆ

**ç—‡çŠ¶**ï¼šé›†ç¾¤é—´é€šä¿¡æ…¢

**è§£å†³**ï¼šä½¿ç”¨Kryoæ›¿ä»£Javaåºåˆ—åŒ–

#### 4. GCé¢‘ç¹

**ç—‡çŠ¶**ï¼šååé‡ä¸‹é™ã€å»¶è¿Ÿå¢åŠ 

**è§£å†³**ï¼š
- å¢å¤§å †å†…å­˜
- ä¼˜åŒ–å¯¹è±¡åˆ†é…
- ä½¿ç”¨ZGCä½å»¶è¿ŸGC

#### 5. Shardåˆ†å¸ƒä¸å‡

**ç—‡çŠ¶**ï¼šæŸäº›èŠ‚ç‚¹è´Ÿè½½è¿‡é«˜

**è§£å†³**ï¼š
```hocon
pekko.cluster.sharding {
  least-shard-allocation-strategy {
    rebalance-threshold = 2
  }
}
```

### æ€§èƒ½ä¼˜åŒ–æ¡ˆä¾‹

**æ¡ˆä¾‹1ï¼šMySQLæ‰¹é‡å†™å…¥**
```
ä¼˜åŒ–å‰ï¼šé€æ¡INSERTï¼Œ100 req/s
ä¼˜åŒ–åï¼šæ‰¹é‡INSERT(1000æ¡)ï¼Œ5000 req/s
æå‡ï¼š50x
```

**æ¡ˆä¾‹2ï¼šStreamså¹¶å‘**
```
ä¼˜åŒ–å‰ï¼šmapAsync(1)ï¼Œ200 req/s
ä¼˜åŒ–åï¼šmapAsync(16) + asyncè¾¹ç•Œï¼Œ3200 req/s
æå‡ï¼š16x
```

**æ¡ˆä¾‹3ï¼šé›†ç¾¤åºåˆ—åŒ–**
```
ä¼˜åŒ–å‰ï¼šJavaåºåˆ—åŒ–ï¼Œ500 msg/s
ä¼˜åŒ–åï¼šKryoåºåˆ—åŒ–ï¼Œ8000 msg/s
æå‡ï¼š16x
```

---

## æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **æµ‹è¯•å…ˆè¡Œ**
   - åŸºå‡†æµ‹è¯•
   - è´Ÿè½½æµ‹è¯•
   - å‹åŠ›æµ‹è¯•
   - æµ¸æ³¡æµ‹è¯•

2. **Actorè°ƒä¼˜**
   - è‡ªå®šä¹‰Dispatcher
   - æ‰¹é‡å¤„ç†
   - é¿å…é˜»å¡

3. **Streamsè°ƒä¼˜**
   - groupedæ‰¹é‡ï¼ˆ50-100xï¼‰
   - mapAsyncå¹¶å‘ï¼ˆ10-20xï¼‰
   - asyncè¾¹ç•Œï¼ˆ2-4xï¼‰

4. **é›†ç¾¤è°ƒä¼˜**
   - é«˜æ•ˆåºåˆ—åŒ–
   - Shardingé…ç½®
   - ç½‘ç»œä¼˜åŒ–

5. **JVMè°ƒä¼˜**
   - G1GC/ZGC
   - å †å†…å­˜é…ç½®
   - GCå‚æ•°

6. **ç›‘æ§å‘Šè­¦**
   - PrometheusæŒ‡æ ‡
   - Grafanaå¯è§†åŒ–
   - å…³é”®å‘Šè­¦

### æ€§èƒ½æå‡æ€»ç»“

| ä¼˜åŒ–é¡¹ | æå‡å€æ•° |
|-------|---------|
| æ‰¹é‡å¤„ç† | **50-100x** |
| å¹¶å‘ä¼˜åŒ– | **10-20x** |
| åºåˆ—åŒ– | **10-16x** |
| å¤šçº¿ç¨‹ | **2-4x** |
| ç¼“å†²åŒº | **1.2-1.3x** |

### ä¸‹ä¸€æ­¥

- **ç¬¬ä¸ƒç¯‡ï¼šç”Ÿäº§ç¯‡** - ç›‘æ§ã€è¿ç»´ä¸æœ€ä½³å®è·µ

---

**é¡¹ç›®åœ°å€**: https://github.com/Xuxiaotuan/pekko-reference

**ä½œè€…**: Xuxiaotuan  
**æ—¥æœŸ**: 2024å¹´11æœˆ

---

*ä¸‹ä¸€ç¯‡ï¼šã€Šç”Ÿäº§ç¯‡ï¼šç›‘æ§è¿ç»´ä¸ä¸Šçº¿æœ€ä½³å®è·µã€‹ï¼ˆå®Œç»“ç¯‡ï¼‰*
